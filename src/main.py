from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from langchain_core.messages import HumanMessage
from pydantic import BaseModel
import uvicorn
import json
from typing import AsyncGenerator, Optional
import sys
from pathlib import Path
import uuid
from langgraph.types import Command
from contextlib import asynccontextmanager

from agents import get_graph  

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ PYTHONPATHì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def serialize_chunk(chunk_data):
    """chunk ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ì§ë ¬í™” (Interrupt ê°ì²´ ì²˜ë¦¬ í¬í•¨)"""
    def default_serializer(obj):
        # Interrupt ê°ì²´ ì²˜ë¦¬
        if hasattr(obj, 'value') and hasattr(obj, 'id'):
            return {'value': obj.value, 'id': str(obj.id)}
        # ê¸°íƒ€ ê°ì²´ëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜
        return str(obj)
    
    try:
        return json.dumps(chunk_data, default=default_serializer, ensure_ascii=False)
    except Exception as e:
        # ì§ë ¬í™” ì‹¤íŒ¨ ì‹œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
        try:
            return json.dumps({'error': f'Serialization error: {str(e)}', 'data': str(chunk_data)}, ensure_ascii=False)
        except:
            return json.dumps({'error': 'Failed to serialize data'}, ensure_ascii=False)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """FastAPI ì•± ì‹œì‘ ë° ì¢…ë£Œ ì‹œ ì‹¤í–‰"""
    # ì‹œì‘: ê·¸ë˜í”„ ì‹±ê¸€í†¤ ì´ˆê¸°í™”
    print("ğŸš€ ê·¸ë˜í”„ ì´ˆê¸°í™” ì¤‘...")
    await get_graph()
    print("âœ… ê·¸ë˜í”„ ì´ˆê¸°í™” ì™„ë£Œ")

    yield  # ì•± ì‹¤í–‰ ì¤‘

    # ì¢…ë£Œ: í•„ìš”ì‹œ ì •ë¦¬ ì‘ì—… ìˆ˜í–‰
    print("ğŸ‘‹ ì•± ì¢…ë£Œ")

app = FastAPI(lifespan=lifespan)

# ì •ì  íŒŒì¼ ì„œë¹™ (HTML í´ë¼ì´ì–¸íŠ¸)
static_dir = project_root / "static"
if static_dir.exists():
    app.mount("/static", StaticFiles(directory=str(static_dir)), name="static")

# CORS ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì ‘ê·¼í•  ê²½ìš°)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class ChatRequest(BaseModel):
    message: str
    thread_id: Optional[str] = None  # ì„¸ì…˜ ê´€ë¦¬ë¥¼ ìœ„í•œ thread_id


class ResumeRequest(BaseModel):
    thread_id: str
    # HITL ìŠ¤íƒ€ì¼ ê²°ì •
    decisions: Optional[list[dict]] = None  # [{"type": "approve|edit|reject", ...}]
    # ë ˆê±°ì‹œ ì§€ì›
    approved: Optional[bool] = None  # ì‚¬ìš©ì ìŠ¹ì¸ ì—¬ë¶€
    user_response: Optional[str] = None  # ì‚¬ìš©ì ì‘ë‹µ (ì¶”ê°€ ì •ë³´ ì œê³µ ì‹œ)


@app.get("/")
async def root():
    """ì±„íŒ… í´ë¼ì´ì–¸íŠ¸ í˜ì´ì§€"""
    static_file = project_root / "static" / "index.html"
    if static_file.exists():
        return FileResponse(str(static_file))
    return {"message": "Hello World", "chat_client": "/static/index.html"}


@app.get("/health")
def health_check():
    return {"status": "ok"}

@app.post("/chat/stream")
async def agent_stream(request: ChatRequest):
    # Thread ID ìƒì„± ë˜ëŠ” ê¸°ì¡´ ID ì‚¬ìš©
    thread_id = request.thread_id or str(uuid.uuid4())

    print(f"ğŸš€ ìŠ¤íŠ¸ë¦¼ ì‹œì‘: {request.message[:50]}... (thread_id: {thread_id})")

    config = {"configurable": {"thread_id": thread_id}}

    async def event_stream():
        try:
            graph = await get_graph()
            # ìŠ¤íŠ¸ë¦¼ ì‹œì‘ ì‹œ thread_idë¥¼ í´ë¼ì´ì–¸íŠ¸ì— ì „ì†¡
            yield f"data: {json.dumps({'event_type': 'thread_id', 'thread_id': thread_id}, ensure_ascii=False)}\n\n"
            
            async for chunk in graph.astream(
                input={"messages": [HumanMessage(content=request.message)]},
                config=config,
                subgraphs=True,
                stream_mode=["updates", "custom"],
            ):
                print(chunk)
                # chunk[-1]ì„ JSONìœ¼ë¡œ ì§ë ¬í™”
                chunk_data = chunk[-1]
                json_str = serialize_chunk(chunk_data)
                yield f"data: {json_str}\n\n"

        except Exception as e:
             yield f"data: {json.dumps({'error': str(e)}, ensure_ascii=False)}\n\n"

    return StreamingResponse(event_stream(), media_type="text/event-stream")
            

@app.post("/chat/resume")
async def resume_interrupt(request: ResumeRequest):
    """Interrupt í›„ ì‚¬ìš©ì ì‘ë‹µìœ¼ë¡œ ì¬ê°œ"""
    try:
        graph = await get_graph()
        config = {"configurable": {"thread_id": request.thread_id}}

        # ë©”ì¸ ë¼ìš°í„°ì—ì„œ í˜„ì¬ ìƒíƒœ í™•ì¸
        main_state = await graph.aget_state(config)

        if not main_state.next or len(main_state.next) == 0:
            raise HTTPException(
                status_code=400,
                detail="No interrupt in progress for this thread"
            )

        # í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ë…¸ë“œ í™•ì¸
        current_node = main_state.next[0] if main_state.next else None

        print(f"ğŸ“ Resume ìš”ì²­: thread_id={request.thread_id}, current_node={current_node}, user_response={request.user_response}")

        # Interruptë¥¼ ì¬ê°œ: resume ê°’ì€ interrupt()ì˜ ë°˜í™˜ê°’ì´ ë¨
        command = Command(
            resume=request.user_response
        )

        async def event_stream():
            """Interrupt ì¬ê°œ í›„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±"""
            try:
                # ìŠ¤íŠ¸ë¦¼ ì‹œì‘ ì‹œ thread_idë¥¼ í´ë¼ì´ì–¸íŠ¸ì— ì „ì†¡
                yield f"data: {json.dumps({'event_type': 'thread_id', 'thread_id': request.thread_id}, ensure_ascii=False)}\n\n"

                # ë©”ì¸ ë¼ìš°í„°ì— ì¬ê°œ ëª…ë ¹ ì „ì†¡
                # ë©”ì¸ ë¼ìš°í„°ê°€ checkpoint ê´€ë¦¬í•˜ë¯€ë¡œ ë©”ì¸ ë¼ìš°í„°ë¥¼ í†µí•´ ì²˜ë¦¬
                async for chunk in graph.astream(
                    command,
                    config,
                    subgraphs=True,
                    stream_mode=["updates", "custom"],
                ):
                    chunk_data = chunk[-1]
                    json_str = serialize_chunk(chunk_data)
                    yield f"data: {json_str}\n\n"

            except Exception as e:
                print(f"âŒ Resume ìŠ¤íŠ¸ë¦¼ ì˜¤ë¥˜: {str(e)}")
                yield f"data: {json.dumps({'error': str(e)}, ensure_ascii=False)}\n\n"

        return StreamingResponse(
            event_stream(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
            }
        )

    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Resume ì—ëŸ¬: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Resume failed: {str(e)}")


@app.get("/chat/status/{thread_id}")
async def get_status(thread_id: str):
    """íŠ¹ì • threadì˜ í˜„ì¬ ìƒíƒœ í™•ì¸"""
    try:
        graph = await get_graph()
        config = {"configurable": {"thread_id": thread_id}}
        state = await graph.aget_state(config)

        return {
            "thread_id": thread_id,
            "next": state.next,
            "values": state.values if state.values else {},
            "interrupted": state.next is not None and len(state.next) > 0
        }
    except Exception as e:
        raise HTTPException(status_code=404, detail=f"Thread not found: {str(e)}")


if __name__ == '__main__':
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=8000,
        log_level="info",
        access_log=False  # ì•¡ì„¸ìŠ¤ ë¡œê·¸ ë¹„í™œì„±í™”ë¡œ ë²„í¼ë§ ê°ì†Œ
    )